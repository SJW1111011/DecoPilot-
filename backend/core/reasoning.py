"""
é«˜çº§æ¨ç†ç³»ç»Ÿ
æ”¯æŒæ€ç»´é“¾(CoT)ã€å¤šæ­¥æ¨ç†ã€è‡ªæˆ‘åæ€ã€æ€ç»´æ ‘(ToT)å’ŒReActæ¨¡å¼
"""
import json
import time
import asyncio
from typing import Any, Dict, List, Optional, Callable, Tuple
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import threading


class ReasoningType(str, Enum):
    """æ¨ç†ç±»å‹"""
    DIRECT = "direct"              # ç›´æ¥å›ç­”
    CHAIN_OF_THOUGHT = "cot"       # æ€ç»´é“¾
    MULTI_STEP = "multi_step"      # å¤šæ­¥æ¨ç†
    TREE_OF_THOUGHT = "tot"        # æ€ç»´æ ‘
    SELF_REFLECTION = "reflection" # è‡ªæˆ‘åæ€
    REACT = "react"                # ReAct æ¨¡å¼ï¼ˆæ¨ç†-è¡ŒåŠ¨-è§‚å¯Ÿå¾ªç¯ï¼‰


class TaskComplexity(str, Enum):
    """ä»»åŠ¡å¤æ‚åº¦"""
    SIMPLE = "simple"       # ç®€å•é—®ç­”
    MODERATE = "moderate"   # ä¸­ç­‰å¤æ‚
    COMPLEX = "complex"     # å¤æ‚æ¨ç†
    EXPERT = "expert"       # ä¸“å®¶çº§


@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    step_id: int
    step_type: str           # think/act/observe/reflect
    content: str
    confidence: float = 0.0
    timestamp: float = field(default_factory=time.time)
    metadata: Dict = field(default_factory=dict)


@dataclass
class ReasoningChain:
    """æ¨ç†é“¾"""
    chain_id: str
    query: str
    reasoning_type: ReasoningType
    steps: List[ReasoningStep] = field(default_factory=list)
    final_answer: Optional[str] = None
    confidence: float = 0.0
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None

    def add_step(self, step_type: str, content: str,
                 confidence: float = 0.0, metadata: Dict = None):
        """æ·»åŠ æ¨ç†æ­¥éª¤"""
        step = ReasoningStep(
            step_id=len(self.steps) + 1,
            step_type=step_type,
            content=content,
            confidence=confidence,
            metadata=metadata or {}
        )
        self.steps.append(step)
        return step

    def get_thinking_log(self) -> List[str]:
        """è·å–æ€è€ƒæ—¥å¿—"""
        logs = []
        for step in self.steps:
            prefix = {
                "think": "ğŸ’­ æ€è€ƒ",
                "act": "ğŸ”§ æ‰§è¡Œ",
                "observe": "ğŸ‘ï¸ è§‚å¯Ÿ",
                "reflect": "ğŸ”„ åæ€",
                "plan": "ğŸ“‹ è§„åˆ’",
                "verify": "âœ… éªŒè¯",
            }.get(step.step_type, "ğŸ“")
            logs.append(f"{prefix}: {step.content}")
        return logs


@dataclass
class Plan:
    """æ‰§è¡Œè®¡åˆ’"""
    plan_id: str
    goal: str
    steps: List[Dict] = field(default_factory=list)
    current_step: int = 0
    status: str = "pending"  # pending/executing/completed/failed

    def add_step(self, action: str, expected_result: str,
                 tools: List[str] = None):
        """æ·»åŠ è®¡åˆ’æ­¥éª¤"""
        self.steps.append({
            "step_id": len(self.steps) + 1,
            "action": action,
            "expected_result": expected_result,
            "tools": tools or [],
            "status": "pending",
            "actual_result": None,
        })

    def next_step(self) -> Optional[Dict]:
        """è·å–ä¸‹ä¸€æ­¥"""
        if self.current_step < len(self.steps):
            return self.steps[self.current_step]
        return None

    def complete_step(self, result: str, success: bool = True):
        """å®Œæˆå½“å‰æ­¥éª¤"""
        if self.current_step < len(self.steps):
            self.steps[self.current_step]["actual_result"] = result
            self.steps[self.current_step]["status"] = "completed" if success else "failed"
            self.current_step += 1


@dataclass
class ThoughtNode:
    """æ€ç»´æ ‘èŠ‚ç‚¹"""
    node_id: str
    content: str
    parent_id: Optional[str] = None
    children: List[str] = field(default_factory=list)
    score: float = 0.0  # è¯„ä¼°åˆ†æ•°
    depth: int = 0
    is_terminal: bool = False
    metadata: Dict = field(default_factory=dict)


@dataclass
class ThoughtTree:
    """æ€ç»´æ ‘"""
    tree_id: str
    query: str
    root_id: str
    nodes: Dict[str, ThoughtNode] = field(default_factory=dict)
    best_path: List[str] = field(default_factory=list)
    max_depth: int = 3
    branching_factor: int = 3

    def add_node(self, content: str, parent_id: str = None,
                 score: float = 0.0) -> ThoughtNode:
        """æ·»åŠ èŠ‚ç‚¹"""
        node_id = f"node_{len(self.nodes)}"
        depth = 0
        if parent_id and parent_id in self.nodes:
            depth = self.nodes[parent_id].depth + 1
            self.nodes[parent_id].children.append(node_id)

        node = ThoughtNode(
            node_id=node_id,
            content=content,
            parent_id=parent_id,
            score=score,
            depth=depth,
        )
        self.nodes[node_id] = node
        return node

    def get_path_to_node(self, node_id: str) -> List[str]:
        """è·å–ä»æ ¹åˆ°æŒ‡å®šèŠ‚ç‚¹çš„è·¯å¾„"""
        path = []
        current_id = node_id
        while current_id:
            path.append(current_id)
            node = self.nodes.get(current_id)
            current_id = node.parent_id if node else None
        return list(reversed(path))

    def get_best_leaf(self) -> Optional[ThoughtNode]:
        """è·å–æœ€ä½³å¶å­èŠ‚ç‚¹"""
        leaves = [n for n in self.nodes.values() if not n.children]
        if not leaves:
            return None
        return max(leaves, key=lambda n: n.score)

    def get_thinking_log(self) -> List[str]:
        """è·å–æ€ç»´æ ‘çš„æ€è€ƒæ—¥å¿—"""
        logs = []
        best_leaf = self.get_best_leaf()
        if best_leaf:
            path = self.get_path_to_node(best_leaf.node_id)
            for i, node_id in enumerate(path):
                node = self.nodes[node_id]
                logs.append(f"ğŸŒ³ æ€è·¯{i+1} (åˆ†æ•°:{node.score:.2f}): {node.content}")
        return logs


@dataclass
class ReActStep:
    """ReAct æ­¥éª¤"""
    step_id: int
    thought: str  # æ€è€ƒ
    action: Optional[str] = None  # è¡ŒåŠ¨
    action_input: Optional[Dict] = None  # è¡ŒåŠ¨è¾“å…¥
    observation: Optional[str] = None  # è§‚å¯Ÿç»“æœ
    timestamp: float = field(default_factory=time.time)


class TaskAnalyzer:
    """ä»»åŠ¡åˆ†æå™¨"""

    # å¤æ‚ä»»åŠ¡å…³é”®è¯ï¼ˆå¸¦æƒé‡ï¼‰
    COMPLEX_KEYWORDS = {
        # åˆ†æç±»ï¼ˆæƒé‡2ï¼‰
        "æ¯”è¾ƒ": 2, "å¯¹æ¯”": 2, "åˆ†æ": 2, "è¯„ä¼°": 2, "è¯„ä»·": 2,
        # è§„åˆ’ç±»ï¼ˆæƒé‡3ï¼‰
        "è§„åˆ’": 3, "è®¾è®¡": 3, "æ–¹æ¡ˆ": 3, "è®¡åˆ’": 2,
        # æ¨ç†ç±»ï¼ˆæƒé‡2ï¼‰
        "å¦‚ä½•": 2, "ä¸ºä»€ä¹ˆ": 2, "æ€ä¹ˆåŠ": 2, "åº”è¯¥": 1,
        # è®¡ç®—ç±»ï¼ˆæƒé‡2ï¼‰
        "å¤šå°‘é’±": 2, "é¢„ç®—": 2, "æŠ¥ä»·": 2, "è®¡ç®—": 2, "èŠ±è´¹": 2,
        # æ¨èç±»ï¼ˆæƒé‡2ï¼‰
        "æ¨è": 2, "å»ºè®®": 2, "é€‰æ‹©": 2, "å“ªä¸ªå¥½": 2,
        # å¤šæ­¥éª¤ç±»ï¼ˆæƒé‡3ï¼‰
        "æ­¥éª¤": 3, "æµç¨‹": 3, "è¿‡ç¨‹": 2, "é¡ºåº": 2,
        # ä¸“ä¸šç±»ï¼ˆæƒé‡3ï¼‰
        "ä¼˜ç¼ºç‚¹": 3, "åˆ©å¼Š": 3, "é£é™©": 2, "æ³¨æ„äº‹é¡¹": 2,
    }

    # ç®€å•ä»»åŠ¡å…³é”®è¯ï¼ˆå¸¦æƒé‡ï¼‰
    SIMPLE_KEYWORDS = {
        # å®šä¹‰ç±»ï¼ˆæƒé‡-2ï¼‰
        "æ˜¯ä»€ä¹ˆ": -2, "ä»€ä¹ˆæ˜¯": -2, "å®šä¹‰": -2, "è§£é‡Š": -1,
        # ä½ç½®ç±»ï¼ˆæƒé‡-2ï¼‰
        "åœ¨å“ª": -2, "å“ªé‡Œ": -2, "åœ°å€": -2, "ä½ç½®": -2,
        # è”ç³»ç±»ï¼ˆæƒé‡-2ï¼‰
        "ç”µè¯": -2, "è”ç³»æ–¹å¼": -2, "å®¢æœ": -1,
        # æ—¶é—´ç±»ï¼ˆæƒé‡-1ï¼‰
        "è¥ä¸šæ—¶é—´": -1, "å¼€æ”¾æ—¶é—´": -1, "å‡ ç‚¹": -1,
        # ç®€å•æŸ¥è¯¢ï¼ˆæƒé‡-1ï¼‰
        "æœ‰æ²¡æœ‰": -1, "æ˜¯å¦": -1, "èƒ½ä¸èƒ½": -1,
    }

    # éœ€è¦å·¥å…·çš„å…³é”®è¯
    TOOL_KEYWORDS = {
        "subsidy_calculator": ["è¡¥è´´", "èƒ½è¡¥å¤šå°‘", "è¿”å¤šå°‘", "ä¼˜æƒ ", "è¿”ç°", "è¡¥è´´é‡‘é¢"],
        "roi_calculator": ["ROI", "æŠ•å…¥äº§å‡º", "å›æŠ¥ç‡", "æ”¶ç›Š", "æŠ•èµ„å›æŠ¥", "ç›ˆåˆ©"],
        "price_evaluator": ["è´µä¸è´µ", "ä»·æ ¼åˆç†", "å€¼ä¸å€¼", "æ€§ä»·æ¯”", "åˆ’ç®—", "ä¾¿å®œ"],
        "decoration_timeline": ["å¤šä¹…", "å·¥æœŸ", "å¤šé•¿æ—¶é—´", "è£…ä¿®æ—¶é—´", "éœ€è¦å‡ å¤©", "å‡ ä¸ªæœˆ"],
    }

    # é¢†åŸŸå¤æ‚åº¦æŒ‡æ ‡
    DOMAIN_COMPLEXITY = {
        # è£…ä¿®ç›¸å…³ï¼ˆé€šå¸¸è¾ƒå¤æ‚ï¼‰
        "è£…ä¿®": 1, "ç¿»æ–°": 1, "æ”¹é€ ": 1,
        # ææ–™ç›¸å…³ï¼ˆä¸­ç­‰å¤æ‚ï¼‰
        "ææ–™": 0.5, "ç“·ç –": 0.5, "åœ°æ¿": 0.5, "æ¶‚æ–™": 0.5,
        # é£æ ¼ç›¸å…³ï¼ˆä¸­ç­‰å¤æ‚ï¼‰
        "é£æ ¼": 0.5, "ç°ä»£": 0.3, "åŒ—æ¬§": 0.3, "ä¸­å¼": 0.3,
        # é¢„ç®—ç›¸å…³ï¼ˆè¾ƒå¤æ‚ï¼‰
        "é¢„ç®—": 1, "è´¹ç”¨": 1, "æˆæœ¬": 1,
    }

    @classmethod
    def analyze_complexity(cls, query: str) -> TaskComplexity:
        """
        åˆ†æä»»åŠ¡å¤æ‚åº¦

        ä½¿ç”¨å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿï¼š
        1. å…³é”®è¯æƒé‡åŒ¹é…
        2. é—®é¢˜ç»“æ„åˆ†æ
        3. é¢†åŸŸå¤æ‚åº¦è¯„ä¼°
        4. è¯­ä¹‰ç‰¹å¾æå–

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            TaskComplexity: ä»»åŠ¡å¤æ‚åº¦ç­‰çº§
        """
        score = 0.0

        # 1. å¤æ‚å…³é”®è¯åŒ¹é…ï¼ˆå¸¦æƒé‡ï¼‰
        for keyword, weight in cls.COMPLEX_KEYWORDS.items():
            if keyword in query:
                score += weight

        # 2. ç®€å•å…³é”®è¯åŒ¹é…ï¼ˆè´Ÿæƒé‡ï¼‰
        for keyword, weight in cls.SIMPLE_KEYWORDS.items():
            if keyword in query:
                score += weight  # weight å·²ç»æ˜¯è´Ÿæ•°

        # 3. é—®é¢˜ç»“æ„åˆ†æ
        # 3.1 é—®é¢˜é•¿åº¦å› å­ï¼ˆé•¿é—®é¢˜é€šå¸¸æ›´å¤æ‚ï¼‰
        length = len(query)
        if length > 100:
            score += 2
        elif length > 50:
            score += 1
        elif length < 15:
            score -= 1

        # 3.2 å¤šé—®é¢˜æ£€æµ‹ï¼ˆåŒ…å«å¤šä¸ªé—®å·ï¼‰
        question_marks = query.count("ï¼Ÿ") + query.count("?")
        if question_marks > 2:
            score += 2
        elif question_marks > 1:
            score += 1

        # 3.3 å¹¶åˆ—ç»“æ„æ£€æµ‹ï¼ˆåŒ…å«"å’Œ"ã€"ä»¥åŠ"ã€"è¿˜æœ‰"ç­‰ï¼‰
        conjunctions = ["å’Œ", "ä»¥åŠ", "è¿˜æœ‰", "å¦å¤–", "åŒæ—¶", "å¹¶ä¸”"]
        conjunction_count = sum(1 for c in conjunctions if c in query)
        score += conjunction_count * 0.5

        # 3.4 æ¡ä»¶ç»“æ„æ£€æµ‹ï¼ˆåŒ…å«"å¦‚æœ"ã€"å‡è®¾"ç­‰ï¼‰
        conditionals = ["å¦‚æœ", "å‡è®¾", "å‡å¦‚", "è¦æ˜¯", "ä¸‡ä¸€"]
        if any(c in query for c in conditionals):
            score += 1.5

        # 4. é¢†åŸŸå¤æ‚åº¦è¯„ä¼°
        for domain, weight in cls.DOMAIN_COMPLEXITY.items():
            if domain in query:
                score += weight

        # 5. æ•°å­—å’Œé‡‘é¢æ£€æµ‹ï¼ˆé€šå¸¸éœ€è¦è®¡ç®—ï¼‰
        import re
        numbers = re.findall(r'\d+(?:\.\d+)?', query)
        if len(numbers) >= 2:
            score += 1  # å¤šä¸ªæ•°å­—å¯èƒ½éœ€è¦æ¯”è¾ƒæˆ–è®¡ç®—
        if any(unit in query for unit in ["ä¸‡", "å…ƒ", "å—", "å¹³ç±³", "ã¡"]):
            score += 0.5

        # 6. æ—¶é—´èŒƒå›´æ£€æµ‹ï¼ˆæ¶‰åŠè§„åˆ’ï¼‰
        time_words = ["å¤šä¹…", "ä»€ä¹ˆæ—¶å€™", "å‡ å¤©", "å‡ ä¸ªæœˆ", "å¤šé•¿æ—¶é—´"]
        if any(tw in query for tw in time_words):
            score += 0.5

        # æ ¹æ®ç»¼åˆè¯„åˆ†ç¡®å®šå¤æ‚åº¦
        if score <= 0:
            return TaskComplexity.SIMPLE
        elif score <= 3:
            return TaskComplexity.MODERATE
        elif score <= 6:
            return TaskComplexity.COMPLEX
        else:
            return TaskComplexity.EXPERT

    @classmethod
    def get_complexity_details(cls, query: str) -> Dict[str, Any]:
        """
        è·å–å¤æ‚åº¦åˆ†æè¯¦æƒ…ï¼ˆç”¨äºè°ƒè¯•å’Œè§£é‡Šï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            åŒ…å«å„ç»´åº¦è¯„åˆ†çš„è¯¦ç»†ä¿¡æ¯
        """
        details = {
            "query": query,
            "scores": {
                "complex_keywords": 0,
                "simple_keywords": 0,
                "length": 0,
                "questions": 0,
                "conjunctions": 0,
                "conditionals": 0,
                "domain": 0,
                "numbers": 0,
            },
            "matched_keywords": [],
            "total_score": 0,
            "complexity": None,
        }

        # å¤æ‚å…³é”®è¯
        for keyword, weight in cls.COMPLEX_KEYWORDS.items():
            if keyword in query:
                details["scores"]["complex_keywords"] += weight
                details["matched_keywords"].append(f"+{keyword}({weight})")

        # ç®€å•å…³é”®è¯
        for keyword, weight in cls.SIMPLE_KEYWORDS.items():
            if keyword in query:
                details["scores"]["simple_keywords"] += weight
                details["matched_keywords"].append(f"{keyword}({weight})")

        # é•¿åº¦
        length = len(query)
        if length > 100:
            details["scores"]["length"] = 2
        elif length > 50:
            details["scores"]["length"] = 1
        elif length < 15:
            details["scores"]["length"] = -1

        # é—®å·
        question_marks = query.count("ï¼Ÿ") + query.count("?")
        if question_marks > 2:
            details["scores"]["questions"] = 2
        elif question_marks > 1:
            details["scores"]["questions"] = 1

        # å¹¶åˆ—ç»“æ„
        conjunctions = ["å’Œ", "ä»¥åŠ", "è¿˜æœ‰", "å¦å¤–", "åŒæ—¶", "å¹¶ä¸”"]
        details["scores"]["conjunctions"] = sum(0.5 for c in conjunctions if c in query)

        # æ¡ä»¶ç»“æ„
        conditionals = ["å¦‚æœ", "å‡è®¾", "å‡å¦‚", "è¦æ˜¯", "ä¸‡ä¸€"]
        if any(c in query for c in conditionals):
            details["scores"]["conditionals"] = 1.5

        # é¢†åŸŸå¤æ‚åº¦
        for domain, weight in cls.DOMAIN_COMPLEXITY.items():
            if domain in query:
                details["scores"]["domain"] += weight

        # æ•°å­—
        import re
        numbers = re.findall(r'\d+(?:\.\d+)?', query)
        if len(numbers) >= 2:
            details["scores"]["numbers"] += 1
        if any(unit in query for unit in ["ä¸‡", "å…ƒ", "å—", "å¹³ç±³", "ã¡"]):
            details["scores"]["numbers"] += 0.5

        # è®¡ç®—æ€»åˆ†
        details["total_score"] = sum(details["scores"].values())
        details["complexity"] = cls.analyze_complexity(query).value

        return details

    @classmethod
    async def analyze_complexity_with_llm(cls, query: str,
                                          llm_caller: Callable) -> TaskComplexity:
        """ä½¿ç”¨ LLM åˆ†æä»»åŠ¡å¤æ‚åº¦"""
        if not llm_caller:
            return cls.analyze_complexity(query)

        prompt = f"""è¯·åˆ†æä»¥ä¸‹é—®é¢˜çš„å¤æ‚åº¦ï¼Œè¿”å›ä¸€ä¸ª JSON å¯¹è±¡ã€‚

é—®é¢˜ï¼š{query}

è¯·è¯„ä¼°ï¼š
1. é—®é¢˜æ˜¯å¦éœ€è¦å¤šæ­¥æ¨ç†ï¼Ÿ
2. é—®é¢˜æ˜¯å¦æ¶‰åŠå¤šä¸ªæ–¹é¢ï¼Ÿ
3. é—®é¢˜æ˜¯å¦éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Ÿ
4. é—®é¢˜æ˜¯å¦éœ€è¦è®¡ç®—æˆ–å·¥å…·ï¼Ÿ

è¿”å›æ ¼å¼ï¼š
{{"complexity": "simple|moderate|complex|expert", "reason": "ç®€çŸ­è¯´æ˜"}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        try:
            response = await llm_caller(prompt)
            # è§£æ JSON
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                complexity_str = data.get("complexity", "moderate")
                return TaskComplexity(complexity_str)
        except Exception:
            pass

        return cls.analyze_complexity(query)

    @classmethod
    def select_reasoning_type(cls, query: str,
                               complexity: TaskComplexity) -> ReasoningType:
        """é€‰æ‹©æ¨ç†ç±»å‹"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å·¥å…·ï¼ˆä½¿ç”¨ ReAct æ¨¡å¼ï¼‰
        for tool, keywords in cls.TOOL_KEYWORDS.items():
            if any(kw in query for kw in keywords):
                return ReasoningType.REACT

        if complexity == TaskComplexity.SIMPLE:
            return ReasoningType.DIRECT
        elif complexity == TaskComplexity.MODERATE:
            return ReasoningType.CHAIN_OF_THOUGHT
        elif complexity == TaskComplexity.COMPLEX:
            return ReasoningType.MULTI_STEP
        else:
            return ReasoningType.TREE_OF_THOUGHT

    @classmethod
    def detect_required_tools(cls, query: str) -> List[str]:
        """æ£€æµ‹é—®é¢˜éœ€è¦çš„å·¥å…·"""
        required_tools = []
        for tool, keywords in cls.TOOL_KEYWORDS.items():
            if any(kw in query for kw in keywords):
                required_tools.append(tool)
        return required_tools

    @classmethod
    def extract_sub_questions(cls, query: str) -> List[str]:
        """æå–å­é—®é¢˜"""
        sub_questions = []

        # æŒ‰æ ‡ç‚¹åˆ†å‰²
        separators = ["ï¼Ÿ", "?", "ï¼Œ", ",", "ï¼›", ";", "ã€"]
        parts = [query]
        for sep in separators:
            new_parts = []
            for part in parts:
                new_parts.extend(part.split(sep))
            parts = new_parts

        # è¿‡æ»¤æœ‰æ•ˆé—®é¢˜
        for part in parts:
            part = part.strip()
            if len(part) > 5:  # è‡³å°‘5ä¸ªå­—ç¬¦
                sub_questions.append(part)

        return sub_questions if len(sub_questions) > 1 else [query]


class ReasoningEngine:
    """æ¨ç†å¼•æ“"""

    def __init__(self, llm_caller: Callable = None):
        """
        åˆå§‹åŒ–æ¨ç†å¼•æ“

        Args:
            llm_caller: LLMè°ƒç”¨å‡½æ•°ï¼Œç­¾åä¸º (prompt: str) -> str
        """
        self.llm_caller = llm_caller
        self.chains: Dict[str, ReasoningChain] = {}
        self.trees: Dict[str, ThoughtTree] = {}
        self._lock = threading.Lock()

    def set_llm_caller(self, llm_caller: Callable):
        """è®¾ç½® LLM è°ƒç”¨å‡½æ•°"""
        self.llm_caller = llm_caller

    def create_chain(self, query: str,
                     reasoning_type: ReasoningType = None) -> ReasoningChain:
        """åˆ›å»ºæ¨ç†é“¾"""
        chain_id = f"chain_{int(time.time() * 1000)}"

        if reasoning_type is None:
            complexity = TaskAnalyzer.analyze_complexity(query)
            reasoning_type = TaskAnalyzer.select_reasoning_type(query, complexity)

        chain = ReasoningChain(
            chain_id=chain_id,
            query=query,
            reasoning_type=reasoning_type
        )
        with self._lock:
            self.chains[chain_id] = chain
        return chain

    def think(self, chain: ReasoningChain, thought: str,
              confidence: float = 0.5) -> ReasoningStep:
        """æ·»åŠ æ€è€ƒæ­¥éª¤"""
        return chain.add_step("think", thought, confidence)

    def act(self, chain: ReasoningChain, action: str,
            tool: str = None) -> ReasoningStep:
        """æ·»åŠ æ‰§è¡Œæ­¥éª¤"""
        return chain.add_step("act", action, metadata={"tool": tool})

    def observe(self, chain: ReasoningChain,
                observation: str) -> ReasoningStep:
        """æ·»åŠ è§‚å¯Ÿæ­¥éª¤"""
        return chain.add_step("observe", observation)

    def reflect(self, chain: ReasoningChain,
                reflection: str, confidence: float = 0.5) -> ReasoningStep:
        """æ·»åŠ åæ€æ­¥éª¤"""
        return chain.add_step("reflect", reflection, confidence)

    def verify(self, chain: ReasoningChain,
               verification: str, passed: bool) -> ReasoningStep:
        """æ·»åŠ éªŒè¯æ­¥éª¤"""
        return chain.add_step("verify", verification,
                              confidence=1.0 if passed else 0.0,
                              metadata={"passed": passed})

    def finalize(self, chain: ReasoningChain, answer: str,
                 confidence: float = 0.8):
        """å®Œæˆæ¨ç†é“¾"""
        chain.final_answer = answer
        chain.confidence = confidence
        chain.end_time = time.time()

    # === æ¨ç†æ¨¡å¼å®ç° ===

    def direct_answer(self, query: str, context: str = "") -> ReasoningChain:
        """ç›´æ¥å›ç­”æ¨¡å¼"""
        chain = self.create_chain(query, ReasoningType.DIRECT)
        self.think(chain, f"è¿™æ˜¯ä¸€ä¸ªç®€å•é—®é¢˜ï¼Œå¯ä»¥ç›´æ¥å›ç­”")
        return chain

    def chain_of_thought(self, query: str, context: str = "") -> ReasoningChain:
        """æ€ç»´é“¾æ¨ç†"""
        chain = self.create_chain(query, ReasoningType.CHAIN_OF_THOUGHT)

        # æ­¥éª¤1: ç†è§£é—®é¢˜
        self.think(chain, f"é¦–å…ˆç†è§£é—®é¢˜ï¼š{query}")

        # æ­¥éª¤2: åˆ†è§£é—®é¢˜
        sub_questions = TaskAnalyzer.extract_sub_questions(query)
        if len(sub_questions) > 1:
            self.think(chain, f"é—®é¢˜å¯ä»¥åˆ†è§£ä¸ºï¼š{', '.join(sub_questions)}")

        # æ­¥éª¤3: æ£€ç´¢ç›¸å…³ä¿¡æ¯
        self.act(chain, "æ£€ç´¢çŸ¥è¯†åº“è·å–ç›¸å…³ä¿¡æ¯", tool="knowledge_search")

        # æ­¥éª¤4: åˆ†æä¿¡æ¯
        self.think(chain, "åˆ†ææ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œæå–å…³é”®ç‚¹")

        # æ­¥éª¤5: ç»¼åˆæ¨ç†
        self.think(chain, "ç»¼åˆä»¥ä¸Šä¿¡æ¯è¿›è¡Œæ¨ç†")

        return chain

    def multi_step_reasoning(self, query: str,
                              context: str = "") -> ReasoningChain:
        """å¤šæ­¥æ¨ç†"""
        chain = self.create_chain(query, ReasoningType.MULTI_STEP)

        # æ­¥éª¤1: é—®é¢˜åˆ†æ
        self.think(chain, f"åˆ†æå¤æ‚é—®é¢˜ï¼š{query}")

        # æ­¥éª¤2: åˆ¶å®šè®¡åˆ’
        self.think(chain, "åˆ¶å®šè§£å†³æ–¹æ¡ˆçš„æ­¥éª¤è®¡åˆ’")

        # æ­¥éª¤3: é€æ­¥æ‰§è¡Œ
        sub_questions = TaskAnalyzer.extract_sub_questions(query)
        for i, sub_q in enumerate(sub_questions, 1):
            self.think(chain, f"æ­¥éª¤{i}: è§£å†³å­é—®é¢˜ - {sub_q}")
            self.act(chain, f"æ‰§è¡Œæ­¥éª¤{i}", tool="knowledge_search")
            self.observe(chain, f"æ­¥éª¤{i}çš„ç»“æœ")

        # æ­¥éª¤4: æ•´åˆç»“æœ
        self.think(chain, "æ•´åˆå„æ­¥éª¤çš„ç»“æœ")

        # æ­¥éª¤5: éªŒè¯ç­”æ¡ˆ
        self.verify(chain, "éªŒè¯ç­”æ¡ˆçš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§", True)

        return chain

    def self_reflection(self, chain: ReasoningChain,
                        initial_answer: str) -> ReasoningChain:
        """è‡ªæˆ‘åæ€"""
        # åæ€1: æ£€æŸ¥ç­”æ¡ˆå®Œæ•´æ€§
        self.reflect(chain, "æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦å®Œæ•´å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜")

        # åæ€2: æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§
        self.reflect(chain, "æ£€æŸ¥æ¨ç†è¿‡ç¨‹æ˜¯å¦æœ‰é€»è¾‘æ¼æ´")

        # åæ€3: æ£€æŸ¥ä¿¡æ¯å‡†ç¡®æ€§
        self.reflect(chain, "æ£€æŸ¥å¼•ç”¨çš„ä¿¡æ¯æ˜¯å¦å‡†ç¡®")

        # åæ€4: æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼
        self.reflect(chain, "æ£€æŸ¥æ˜¯å¦æœ‰é‡è¦ä¿¡æ¯è¢«é—æ¼")

        return chain

    # === Tree of Thought å®ç° ===

    def create_thought_tree(self, query: str, max_depth: int = 3,
                            branching_factor: int = 3) -> ThoughtTree:
        """åˆ›å»ºæ€ç»´æ ‘"""
        tree_id = f"tree_{int(time.time() * 1000)}"
        root_id = "node_0"

        tree = ThoughtTree(
            tree_id=tree_id,
            query=query,
            root_id=root_id,
            max_depth=max_depth,
            branching_factor=branching_factor,
        )

        # åˆ›å»ºæ ¹èŠ‚ç‚¹
        tree.add_node(f"åˆ†æé—®é¢˜: {query}", score=0.5)

        with self._lock:
            self.trees[tree_id] = tree

        return tree

    async def expand_thought_tree(self, tree: ThoughtTree,
                                   node_id: str = None) -> List[ThoughtNode]:
        """æ‰©å±•æ€ç»´æ ‘èŠ‚ç‚¹"""
        if node_id is None:
            node_id = tree.root_id

        node = tree.nodes.get(node_id)
        if not node or node.depth >= tree.max_depth:
            return []

        if not self.llm_caller:
            # æ²¡æœ‰ LLMï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆå­èŠ‚ç‚¹
            return self._expand_with_rules(tree, node)

        # ä½¿ç”¨ LLM ç”Ÿæˆå¤šä¸ªæ€è·¯
        prompt = f"""é’ˆå¯¹ä»¥ä¸‹é—®é¢˜ï¼Œè¯·æä¾› {tree.branching_factor} ä¸ªä¸åŒçš„æ€è€ƒæ–¹å‘ã€‚

é—®é¢˜ï¼š{tree.query}
å½“å‰æ€è·¯ï¼š{node.content}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{"thoughts": ["æ€è·¯1", "æ€è·¯2", "æ€è·¯3"]}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        try:
            response = await self.llm_caller(prompt)
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                thoughts = data.get("thoughts", [])

                new_nodes = []
                for thought in thoughts[:tree.branching_factor]:
                    new_node = tree.add_node(thought, parent_id=node_id, score=0.5)
                    new_nodes.append(new_node)
                return new_nodes
        except Exception:
            pass

        return self._expand_with_rules(tree, node)

    def _expand_with_rules(self, tree: ThoughtTree,
                           node: ThoughtNode) -> List[ThoughtNode]:
        """ä½¿ç”¨è§„åˆ™æ‰©å±•èŠ‚ç‚¹"""
        templates = [
            f"ä»ç”¨æˆ·éœ€æ±‚è§’åº¦åˆ†æ: {tree.query}",
            f"ä»ä¸“ä¸šçŸ¥è¯†è§’åº¦åˆ†æ: {tree.query}",
            f"ä»å®é™…æ“ä½œè§’åº¦åˆ†æ: {tree.query}",
        ]

        new_nodes = []
        for template in templates[:tree.branching_factor]:
            new_node = tree.add_node(template, parent_id=node.node_id, score=0.5)
            new_nodes.append(new_node)
        return new_nodes

    async def evaluate_thought_node(self, tree: ThoughtTree,
                                     node_id: str) -> float:
        """è¯„ä¼°æ€ç»´èŠ‚ç‚¹çš„è´¨é‡"""
        node = tree.nodes.get(node_id)
        if not node:
            return 0.0

        if not self.llm_caller:
            # ç®€å•è¯„ä¼°ï¼šåŸºäºæ·±åº¦å’Œå†…å®¹é•¿åº¦
            return 0.5 + (node.depth * 0.1) + (len(node.content) / 200)

        prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹æ€è·¯å¯¹äºè§£å†³é—®é¢˜çš„å¸®åŠ©ç¨‹åº¦ã€‚

é—®é¢˜ï¼š{tree.query}
æ€è·¯ï¼š{node.content}

è¯·è¿”å› 0-1 ä¹‹é—´çš„åˆ†æ•°ï¼Œæ ¼å¼ï¼š{{"score": 0.8, "reason": "ç®€çŸ­è¯´æ˜"}}
åªè¿”å› JSONã€‚"""

        try:
            response = await self.llm_caller(prompt)
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                score = float(data.get("score", 0.5))
                node.score = score
                return score
        except Exception:
            pass

        return 0.5

    def tree_of_thought(self, query: str, context: str = "") -> ReasoningChain:
        """æ€ç»´æ ‘æ¨ç†ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        chain = self.create_chain(query, ReasoningType.TREE_OF_THOUGHT)
        tree = self.create_thought_tree(query)

        # è®°å½•æ€ç»´æ ‘åˆ›å»º
        self.think(chain, f"åˆ›å»ºæ€ç»´æ ‘åˆ†æå¤æ‚é—®é¢˜")

        # ä½¿ç”¨è§„åˆ™æ‰©å±•
        root_node = tree.nodes[tree.root_id]
        child_nodes = self._expand_with_rules(tree, root_node)

        for node in child_nodes:
            self.think(chain, f"æ¢ç´¢æ€è·¯: {node.content}", confidence=node.score)

        # é€‰æ‹©æœ€ä½³è·¯å¾„
        best_leaf = tree.get_best_leaf()
        if best_leaf:
            self.think(chain, f"é€‰æ‹©æœ€ä½³æ€è·¯: {best_leaf.content}")

        return chain

    # === ReAct æ¨¡å¼å®ç° ===

    def react_reasoning(self, query: str, context: str = "",
                        available_tools: List[str] = None) -> ReasoningChain:
        """ReAct æ¨ç†æ¨¡å¼"""
        chain = self.create_chain(query, ReasoningType.REACT)

        # æ£€æµ‹éœ€è¦çš„å·¥å…·
        required_tools = TaskAnalyzer.detect_required_tools(query)

        # æ­¥éª¤1: æ€è€ƒ
        self.think(chain, f"åˆ†æé—®é¢˜ï¼Œç¡®å®šéœ€è¦çš„ä¿¡æ¯å’Œå·¥å…·")

        if required_tools:
            self.think(chain, f"æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨å·¥å…·: {', '.join(required_tools)}")

        # æ­¥éª¤2: è¡ŒåŠ¨
        for tool in required_tools:
            self.act(chain, f"è°ƒç”¨å·¥å…· {tool}", tool=tool)

        # æ­¥éª¤3: è§‚å¯Ÿ
        self.observe(chain, "ç­‰å¾…å·¥å…·è¿”å›ç»“æœ")

        # æ­¥éª¤4: ç»§ç»­æ€è€ƒ
        self.think(chain, "æ ¹æ®å·¥å…·ç»“æœè¿›è¡Œæ¨ç†")

        return chain

    def create_plan(self, goal: str) -> Plan:
        """åˆ›å»ºæ‰§è¡Œè®¡åˆ’"""
        plan_id = f"plan_{int(time.time() * 1000)}"
        return Plan(plan_id=plan_id, goal=goal)


# === æ¨ç†æç¤ºè¯æ¨¡æ¿ ===

COT_PROMPT_TEMPLATE = """è¯·ä½¿ç”¨æ€ç»´é“¾æ–¹æ³•å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚

é—®é¢˜ï¼š{query}

å‚è€ƒä¿¡æ¯ï¼š
{context}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ€è€ƒï¼š
1. é¦–å…ˆç†è§£é—®é¢˜çš„æ ¸å¿ƒæ˜¯ä»€ä¹ˆ
2. åˆ†æé—®é¢˜æ¶‰åŠå“ªäº›æ–¹é¢
3. ä»å‚è€ƒä¿¡æ¯ä¸­æå–ç›¸å…³å†…å®¹
4. é€æ­¥æ¨ç†å¾—å‡ºç­”æ¡ˆ
5. éªŒè¯ç­”æ¡ˆçš„åˆç†æ€§

è¯·åœ¨å›ç­”ä¸­å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚
"""

MULTI_STEP_PROMPT_TEMPLATE = """è¯·ä½¿ç”¨å¤šæ­¥æ¨ç†æ–¹æ³•å›ç­”ä»¥ä¸‹å¤æ‚é—®é¢˜ã€‚

é—®é¢˜ï¼š{query}

å‚è€ƒä¿¡æ¯ï¼š
{context}

è¯·æŒ‰ä»¥ä¸‹æ–¹å¼å¤„ç†ï¼š
1. å°†é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªå­é—®é¢˜
2. é€ä¸€è§£å†³æ¯ä¸ªå­é—®é¢˜
3. æ•´åˆå„å­é—®é¢˜çš„ç­”æ¡ˆ
4. å½¢æˆå®Œæ•´çš„æœ€ç»ˆç­”æ¡ˆ

å­é—®é¢˜ï¼š
{sub_questions}

è¯·é€æ­¥å›ç­”æ¯ä¸ªå­é—®é¢˜ï¼Œç„¶åç»™å‡ºç»¼åˆç­”æ¡ˆã€‚
"""

REFLECTION_PROMPT_TEMPLATE = """è¯·å¯¹ä»¥ä¸‹å›ç­”è¿›è¡Œè‡ªæˆ‘åæ€å’Œæ”¹è¿›ã€‚

åŸå§‹é—®é¢˜ï¼š{query}

åˆå§‹å›ç­”ï¼š{initial_answer}

è¯·æ£€æŸ¥ï¼š
1. å›ç­”æ˜¯å¦å®Œæ•´ï¼Ÿæ˜¯å¦é—æ¼äº†é‡è¦ä¿¡æ¯ï¼Ÿ
2. æ¨ç†æ˜¯å¦æ­£ç¡®ï¼Ÿæ˜¯å¦æœ‰é€»è¾‘é”™è¯¯ï¼Ÿ
3. ä¿¡æ¯æ˜¯å¦å‡†ç¡®ï¼Ÿæ˜¯å¦éœ€è¦ä¿®æ­£ï¼Ÿ
4. è¡¨è¾¾æ˜¯å¦æ¸…æ™°ï¼Ÿæ˜¯å¦éœ€è¦æ”¹è¿›ï¼Ÿ

å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·æä¾›æ”¹è¿›åçš„å›ç­”ã€‚
"""

REACT_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä½¿ç”¨ ReActï¼ˆæ¨ç†-è¡ŒåŠ¨-è§‚å¯Ÿï¼‰æ¨¡å¼æ¥è§£å†³é—®é¢˜ã€‚

é—®é¢˜ï¼š{query}

å¯ç”¨å·¥å…·ï¼š
{tools_description}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼æ€è€ƒå’Œè¡ŒåŠ¨ï¼š

æ€è€ƒï¼šåˆ†æé—®é¢˜ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
è¡ŒåŠ¨ï¼šé€‰æ‹©è¦ä½¿ç”¨çš„å·¥å…·å’Œå‚æ•°
è§‚å¯Ÿï¼šæŸ¥çœ‹å·¥å…·è¿”å›çš„ç»“æœ
... (é‡å¤ç›´åˆ°å¾—å‡ºç­”æ¡ˆ)
ç­”æ¡ˆï¼šæœ€ç»ˆç­”æ¡ˆ

å‚è€ƒä¿¡æ¯ï¼š
{context}

è¯·å¼€å§‹ä½ çš„æ¨ç†è¿‡ç¨‹ã€‚
"""

TOT_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä½¿ç”¨æ€ç»´æ ‘ï¼ˆTree of Thoughtï¼‰æ–¹æ³•æ¥è§£å†³å¤æ‚é—®é¢˜ã€‚

é—®é¢˜ï¼š{query}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ€è€ƒï¼š

1. ç”Ÿæˆå¤šä¸ªå¯èƒ½çš„æ€è·¯æ–¹å‘
2. è¯„ä¼°æ¯ä¸ªæ€è·¯çš„å¯è¡Œæ€§å’Œæ½œåœ¨ä»·å€¼
3. é€‰æ‹©æœ€æœ‰å‰æ™¯çš„æ€è·¯æ·±å…¥æ¢ç´¢
4. å¦‚æœé‡åˆ°æ­»èƒ¡åŒï¼Œå›æº¯å¹¶å°è¯•å…¶ä»–æ€è·¯
5. ç»¼åˆæœ€ä½³è·¯å¾„å¾—å‡ºç­”æ¡ˆ

å‚è€ƒä¿¡æ¯ï¼š
{context}

è¯·å±•ç¤ºä½ çš„æ€ç»´æ ‘æ¢ç´¢è¿‡ç¨‹ã€‚
"""


def get_reasoning_prompt(reasoning_type: ReasoningType, query: str,
                         context: str = "", **kwargs) -> str:
    """è·å–æ¨ç†æç¤ºè¯"""
    if reasoning_type == ReasoningType.CHAIN_OF_THOUGHT:
        return COT_PROMPT_TEMPLATE.format(query=query, context=context)
    elif reasoning_type == ReasoningType.MULTI_STEP:
        sub_questions = kwargs.get("sub_questions", [query])
        sub_q_text = "\n".join(f"- {q}" for q in sub_questions)
        return MULTI_STEP_PROMPT_TEMPLATE.format(
            query=query, context=context, sub_questions=sub_q_text
        )
    elif reasoning_type == ReasoningType.SELF_REFLECTION:
        initial_answer = kwargs.get("initial_answer", "")
        return REFLECTION_PROMPT_TEMPLATE.format(
            query=query, initial_answer=initial_answer
        )
    elif reasoning_type == ReasoningType.REACT:
        tools_description = kwargs.get("tools_description", "æ— å¯ç”¨å·¥å…·")
        return REACT_PROMPT_TEMPLATE.format(
            query=query, context=context, tools_description=tools_description
        )
    elif reasoning_type == ReasoningType.TREE_OF_THOUGHT:
        return TOT_PROMPT_TEMPLATE.format(query=query, context=context)
    else:
        return f"é—®é¢˜ï¼š{query}\n\nå‚è€ƒä¿¡æ¯ï¼š{context}"


# å…¨å±€æ¨ç†å¼•æ“å®ä¾‹
_reasoning_engine: Optional[ReasoningEngine] = None


def get_reasoning_engine() -> ReasoningEngine:
    """è·å–å…¨å±€æ¨ç†å¼•æ“"""
    global _reasoning_engine
    if _reasoning_engine is None:
        _reasoning_engine = ReasoningEngine()
    return _reasoning_engine


# === æ¨ç†ç»“æœæ ¼å¼åŒ– ===

class ReasoningFormatter:
    """æ¨ç†è¿‡ç¨‹æ ¼å¼åŒ–å™¨"""

    @staticmethod
    def format_chain_for_display(chain: ReasoningChain) -> Dict:
        """
        å°†æ¨ç†é“¾æ ¼å¼åŒ–ä¸ºå¯å±•ç¤ºçš„ç»“æ„

        Returns:
            åŒ…å«æ¨ç†è¿‡ç¨‹çš„ç»“æ„åŒ–æ•°æ®
        """
        return {
            "chain_id": chain.chain_id,
            "query": chain.query,
            "reasoning_type": chain.reasoning_type.value,
            "reasoning_type_name": {
                "direct": "ç›´æ¥å›ç­”",
                "cot": "æ€ç»´é“¾æ¨ç†",
                "multi_step": "å¤šæ­¥æ¨ç†",
                "tot": "æ€ç»´æ ‘æ¢ç´¢",
                "reflection": "è‡ªæˆ‘åæ€",
                "react": "æ¨ç†-è¡ŒåŠ¨å¾ªç¯",
            }.get(chain.reasoning_type.value, chain.reasoning_type.value),
            "steps": [
                {
                    "step_id": step.step_id,
                    "type": step.step_type,
                    "type_icon": {
                        "think": "ğŸ’­",
                        "act": "ğŸ”§",
                        "observe": "ğŸ‘ï¸",
                        "reflect": "ğŸ”„",
                        "plan": "ğŸ“‹",
                        "verify": "âœ…",
                    }.get(step.step_type, "ğŸ“"),
                    "content": step.content,
                    "confidence": step.confidence,
                }
                for step in chain.steps
            ],
            "final_answer": chain.final_answer,
            "confidence": chain.confidence,
            "duration": (chain.end_time - chain.start_time) if chain.end_time else None,
        }

    @staticmethod
    def format_chain_as_markdown(chain: ReasoningChain) -> str:
        """
        å°†æ¨ç†é“¾æ ¼å¼åŒ–ä¸º Markdown æ–‡æœ¬

        Returns:
            Markdown æ ¼å¼çš„æ¨ç†è¿‡ç¨‹
        """
        lines = []
        lines.append(f"## æ¨ç†è¿‡ç¨‹")
        lines.append(f"**æ¨ç†ç±»å‹**: {chain.reasoning_type.value}")
        lines.append("")

        for step in chain.steps:
            icon = {
                "think": "ğŸ’­",
                "act": "ğŸ”§",
                "observe": "ğŸ‘ï¸",
                "reflect": "ğŸ”„",
                "plan": "ğŸ“‹",
                "verify": "âœ…",
            }.get(step.step_type, "ğŸ“")

            lines.append(f"{icon} **{step.step_type}**: {step.content}")

        if chain.final_answer:
            lines.append("")
            lines.append(f"**ç»“è®º**: {chain.final_answer}")

        if chain.confidence > 0:
            lines.append(f"**ç½®ä¿¡åº¦**: {chain.confidence:.0%}")

        return "\n".join(lines)

    @staticmethod
    def get_reasoning_summary(chain: ReasoningChain) -> str:
        """
        è·å–æ¨ç†è¿‡ç¨‹çš„ç®€çŸ­æ‘˜è¦

        Returns:
            æ¨ç†æ‘˜è¦æ–‡æœ¬
        """
        type_names = {
            "direct": "ç›´æ¥å›ç­”",
            "cot": "æ€ç»´é“¾åˆ†æ",
            "multi_step": "å¤šæ­¥æ¨ç†",
            "tot": "å¤šè·¯å¾„æ¢ç´¢",
            "reflection": "åæ€ä¼˜åŒ–",
            "react": "å·¥å…·è¾…åŠ©æ¨ç†",
        }

        type_name = type_names.get(chain.reasoning_type.value, "æ¨ç†")
        step_count = len(chain.steps)

        if step_count == 0:
            return f"ä½¿ç”¨{type_name}æ¨¡å¼"
        elif step_count <= 3:
            return f"ç»è¿‡{step_count}æ­¥{type_name}"
        else:
            return f"ç»è¿‡{step_count}æ­¥æ·±åº¦{type_name}"


class AdaptiveReasoningStrategy:
    """è‡ªé€‚åº”æ¨ç†ç­–ç•¥"""

    def __init__(self, engine: ReasoningEngine):
        self.engine = engine
        self._history: List[Dict] = []
        self._max_history = 100

    def select_strategy(self, query: str, context: Dict = None) -> ReasoningType:
        """
        æ ¹æ®æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡è‡ªé€‚åº”é€‰æ‹©æ¨ç†ç­–ç•¥

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç”¨æˆ·ç”»åƒã€å†å²ç­‰ï¼‰

        Returns:
            æ¨èçš„æ¨ç†ç±»å‹
        """
        # åŸºç¡€å¤æ‚åº¦åˆ†æ
        complexity = TaskAnalyzer.analyze_complexity(query)
        base_type = TaskAnalyzer.select_reasoning_type(query, complexity)

        # æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´
        if context:
            # å¦‚æœç”¨æˆ·åå¥½è¯¦ç»†è§£é‡Šï¼Œæå‡æ¨ç†å¤æ‚åº¦
            if context.get("user_profile", {}).get("response_detail_level") == "detailed":
                if base_type == ReasoningType.DIRECT:
                    base_type = ReasoningType.CHAIN_OF_THOUGHT
                elif base_type == ReasoningType.CHAIN_OF_THOUGHT:
                    base_type = ReasoningType.MULTI_STEP

            # å¦‚æœæœ‰å·¥å…·ç»“æœï¼Œä½¿ç”¨ ReAct æ¨¡å¼
            if context.get("tool_results"):
                base_type = ReasoningType.REACT

            # å¦‚æœæ˜¯å¤æ‚çš„å¤šæ–¹é¢é—®é¢˜ï¼Œä½¿ç”¨æ€ç»´æ ‘
            if context.get("is_multi_aspect"):
                base_type = ReasoningType.TREE_OF_THOUGHT

        return base_type

    def record_result(self, query: str, reasoning_type: ReasoningType,
                      success: bool, user_feedback: float = None):
        """
        è®°å½•æ¨ç†ç»“æœï¼Œç”¨äºç­–ç•¥ä¼˜åŒ–

        Args:
            query: æŸ¥è¯¢
            reasoning_type: ä½¿ç”¨çš„æ¨ç†ç±»å‹
            success: æ˜¯å¦æˆåŠŸ
            user_feedback: ç”¨æˆ·åé¦ˆè¯„åˆ† (0-1)
        """
        self._history.append({
            "query": query,
            "reasoning_type": reasoning_type.value,
            "success": success,
            "feedback": user_feedback,
            "timestamp": time.time(),
        })

        # é™åˆ¶å†å²è®°å½•å¤§å°
        if len(self._history) > self._max_history:
            self._history = self._history[-self._max_history:]

    def get_statistics(self) -> Dict:
        """è·å–æ¨ç†ç­–ç•¥ç»Ÿè®¡"""
        if not self._history:
            return {"total": 0}

        stats = {
            "total": len(self._history),
            "by_type": {},
            "success_rate": 0,
            "avg_feedback": 0,
        }

        success_count = 0
        feedback_sum = 0
        feedback_count = 0

        for record in self._history:
            rt = record["reasoning_type"]
            if rt not in stats["by_type"]:
                stats["by_type"][rt] = {"count": 0, "success": 0}
            stats["by_type"][rt]["count"] += 1
            if record["success"]:
                stats["by_type"][rt]["success"] += 1
                success_count += 1
            if record["feedback"] is not None:
                feedback_sum += record["feedback"]
                feedback_count += 1

        stats["success_rate"] = success_count / len(self._history)
        if feedback_count > 0:
            stats["avg_feedback"] = feedback_sum / feedback_count

        return stats


# å…¨å±€è‡ªé€‚åº”ç­–ç•¥å®ä¾‹
_adaptive_strategy: Optional[AdaptiveReasoningStrategy] = None


def get_adaptive_strategy() -> AdaptiveReasoningStrategy:
    """è·å–å…¨å±€è‡ªé€‚åº”æ¨ç†ç­–ç•¥"""
    global _adaptive_strategy
    if _adaptive_strategy is None:
        _adaptive_strategy = AdaptiveReasoningStrategy(get_reasoning_engine())
    return _adaptive_strategy
