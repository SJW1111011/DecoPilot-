"""
ä¸“å®¶è§’è‰² A/B å¯¹æ¯”å·¥å…·

å¯¹åŒä¸€ä¸ªç”¨æˆ·é—®é¢˜ï¼Œåˆ†åˆ«ç”¨"é€šç”¨è£…ä¿®é¡¾é—®"å’Œ"é˜¶æ®µä¸“å®¶"ç”Ÿæˆå›ç­”ï¼Œå¹¶æ’å±•ç¤ºå¯¹æ¯”ã€‚

ç”¨æ³•:
    python tests/eval_expert_comparison.py                    # è¿è¡Œæ‰€æœ‰å¯¹æ¯”æµ‹è¯•
    python tests/eval_expert_comparison.py --case 0           # åªè¿è¡Œç¬¬0ä¸ªæµ‹è¯•
    python tests/eval_expert_comparison.py --custom "ä½ çš„é—®é¢˜"  # è‡ªå®šä¹‰é—®é¢˜
"""
import os
import sys
import asyncio
import argparse
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.core.stage_reasoning import (
    StageAwareReasoning, StageContext, ExpertRole,
)


# ============ å¯¹æ¯”æµ‹è¯•ç”¨ä¾‹ ============

COMPARISON_CASES = [
    {
        "query": "ç“·ç –è´´å®Œå‘ç°æœ‰ç©ºé¼“ï¼Œå·¥äººè¯´æ²¡é—®é¢˜",
        "description": "æ–½å·¥è´¨é‡é—®é¢˜ â€” ç©ºé¼“",
    },
    {
        "query": "æˆ‘å®¶120å¹³ï¼Œé¢„ç®—20ä¸‡ï¼Œä¸çŸ¥é“ä»å“ªå¼€å§‹",
        "description": "å‡†å¤‡é˜¶æ®µ â€” æ–°æ‰‹å…¥é—¨",
    },
    {
        "query": "è®¾è®¡å¸ˆç»™äº†ä¸¤ä¸ªæ–¹æ¡ˆï¼Œä¸€ä¸ªç°ä»£ç®€çº¦ä¸€ä¸ªåŒ—æ¬§é£ï¼Œä¸çŸ¥é“é€‰å“ªä¸ª",
        "description": "è®¾è®¡é˜¶æ®µ â€” æ–¹æ¡ˆé€‰æ‹©",
    },
    {
        "query": "å®¢å…æ²™å‘é€‰ä»€ä¹ˆé¢œè‰²å¥½ï¼Œå¢™æ˜¯ç™½è‰²çš„ï¼Œåœ°æ¿æ˜¯æµ…æœ¨è‰²",
        "description": "è½¯è£…é˜¶æ®µ â€” é¢œè‰²æ­é…",
    },
    {
        "query": "è£…ä¿®å®Œ3ä¸ªæœˆäº†ï¼Œæµ‹äº†ç”²é†›0.12ï¼Œèƒ½ä½å—",
        "description": "å…¥ä½é˜¶æ®µ â€” ç”²é†›é—®é¢˜",
    },
    {
        "query": "é˜²æ°´åšå®Œäº†ï¼Œé—­æ°´è¯•éªŒè¦åšå¤šä¹…ï¼Ÿæ¥¼ä¸‹è¯´æœ‰ç‚¹æ¸—æ°´",
        "description": "æ–½å·¥é˜¶æ®µ â€” é˜²æ°´éªŒæ”¶",
    },
    {
        "query": "æœ€è¿‘è½¬åŒ–ç‡ä»15%é™åˆ°8%äº†ï¼Œä¸çŸ¥é“å“ªé‡Œå‡ºäº†é—®é¢˜",
        "description": "Bç«¯è·å®¢ â€” è½¬åŒ–ç‡ä¸‹é™",
    },
    {
        "query": "æˆ‘æ˜¯åšå…¨å±‹å®šåˆ¶çš„ï¼Œæƒ³äº†è§£å…¥é©»æ¡ä»¶å’Œè´¹ç”¨",
        "description": "Bç«¯å…¥é©» â€” å…¥é©»å’¨è¯¢",
    },
]


# ============ é€šç”¨ç³»ç»Ÿæç¤ºè¯ ============

GENERIC_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è£…ä¿®é¡¾é—®ï¼Œè¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
å¦‚æœæ¶‰åŠå…·ä½“æ•°æ®æˆ–æ ‡å‡†ï¼Œè¯·å°½é‡ç»™å‡ºå‡†ç¡®ä¿¡æ¯ã€‚
å›ç­”è¦å®ç”¨ã€å…·ä½“ã€æœ‰å¯æ“ä½œæ€§ã€‚"""

GENERIC_B_END_PROMPT = """ä½ æ˜¯ä¸€ä¸ªå¹³å°å•†å®¶åŠ©æ‰‹ï¼Œå¸®åŠ©å•†å®¶è§£ç­”ç»è¥ç›¸å…³é—®é¢˜ã€‚
å›ç­”è¦ä¸“ä¸šã€åŠ¡å®ï¼Œæ³¨é‡æ•°æ®å’Œæ•ˆæœã€‚"""


# ============ å¯¹æ¯”å¼•æ“ ============

async def generate_response(llm, system_prompt: str, query: str) -> str:
    """ä½¿ç”¨æŒ‡å®šçš„ç³»ç»Ÿæç¤ºè¯ç”Ÿæˆå›ç­”"""
    from langchain_core.messages import SystemMessage, HumanMessage

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=query),
    ]

    response = await llm.ainvoke(messages)
    return response.content if hasattr(response, 'content') else str(response)


async def run_comparison(llm, reasoning: StageAwareReasoning, query: str,
                         description: str, index: int):
    """è¿è¡Œå•ä¸ªå¯¹æ¯”æµ‹è¯•"""
    width = 70

    # 1. é˜¶æ®µåˆ†æ
    user_type = "b_end" if "è½¬åŒ–ç‡" in query or "å…¥é©»" in query or "è·å®¢" in query else "c_end"

    context, expert, transition = await reasoning.analyze_and_get_expert(
        query=query,
        conversation_history=[],
        user_profile={},
        previous_stage=None,
        user_type=user_type,
    )

    expert_name = expert.name if expert else "é€šç”¨é¡¾é—®"
    expert_prompt = expert.system_prompt if expert else ""

    # å¦‚æœæœ‰ä¸“å®¶ï¼Œè·å–å®šåˆ¶åŒ–çš„æç¤ºè¯ï¼ˆåŒ…å«æƒ…ç»ªã€å…³æ³¨ç‚¹ç­‰ï¼‰
    if expert:
        expert_prompt = reasoning.get_expert_system_prompt(
            stage=context.stage,
            user_type=user_type,
            context=context,
        )

    # 2. ç¡®å®šé€šç”¨æç¤ºè¯
    generic_prompt = GENERIC_SYSTEM_PROMPT if user_type == "c_end" else GENERIC_B_END_PROMPT

    # 3. å¹¶è¡Œç”Ÿæˆä¸¤ä¸ªå›ç­”
    generic_response, expert_response = await asyncio.gather(
        generate_response(llm, generic_prompt, query),
        generate_response(llm, expert_prompt, query) if expert_prompt else asyncio.coroutine(lambda: "ï¼ˆæ— ä¸“å®¶æç¤ºè¯ï¼‰")(),
    )

    # 4. è¾“å‡ºå¯¹æ¯”ç»“æœ
    print("\n" + "â”" * width)
    print(f"ğŸ“‹ æµ‹è¯• #{index}: {description}")
    print(f"ğŸ¯ æ£€æµ‹é˜¶æ®µ: {context.stage} (ç½®ä¿¡åº¦: {context.stage_confidence:.0%})")
    print(f"ğŸ‘¤ ä¸“å®¶è§’è‰²: {expert_name}")
    if context.emotional_state and context.emotional_state != "å¹³é™":
        print(f"ğŸ’­ ç”¨æˆ·æƒ…ç»ª: {context.emotional_state}")
    if context.focus_points:
        print(f"ğŸ” å…³æ³¨é‡ç‚¹: {', '.join(context.focus_points)}")
    print(f"\nğŸ’¬ ç”¨æˆ·é—®é¢˜: {query}")

    print(f"\n{'â”€' * width}")
    print(f"ã€é€šç”¨è£…ä¿®é¡¾é—®çš„å›ç­”ã€‘")
    print(f"{'â”€' * width}")
    print(generic_response)

    print(f"\n{'â”€' * width}")
    print(f"ã€{expert_name}çš„å›ç­”ã€‘")
    print(f"{'â”€' * width}")
    print(expert_response)

    print("â”" * width)

    return {
        "query": query,
        "description": description,
        "stage": context.stage,
        "confidence": context.stage_confidence,
        "expert": expert_name,
        "generic_length": len(generic_response),
        "expert_length": len(expert_response),
    }


# ============ ä¸»å‡½æ•° ============

async def run_all_comparisons(cases: list, case_index: int = None):
    """è¿è¡Œæ‰€æœ‰å¯¹æ¯”æµ‹è¯•"""
    try:
        from langchain_community.chat_models import ChatTongyi
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… langchain-community: pip install langchain-community")
        return

    print("\nğŸ”§ åˆå§‹åŒ– LLM...")
    try:
        llm = ChatTongyi(model="qwen-plus", temperature=0.7)
        # åˆ›å»º llm_caller åŒ…è£…
        async def _llm_caller(prompt: str) -> str:
            response = await llm.ainvoke(prompt)
            return response.content if hasattr(response, 'content') else str(response)

        reasoning = StageAwareReasoning(llm_caller=_llm_caller)
        print("âœ… LLM åˆå§‹åŒ–æˆåŠŸ (qwen-plus)")
    except Exception as e:
        print(f"âŒ LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿è®¾ç½®äº† DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        return

    # é€‰æ‹©è¦è¿è¡Œçš„ç”¨ä¾‹
    if case_index is not None:
        if 0 <= case_index < len(cases):
            cases_to_run = [(case_index, cases[case_index])]
        else:
            print(f"âŒ æ— æ•ˆçš„ç”¨ä¾‹ç´¢å¼•: {case_index} (å…± {len(cases)} ä¸ªç”¨ä¾‹)")
            return
    else:
        cases_to_run = list(enumerate(cases))

    print(f"\nğŸ“Š å…± {len(cases_to_run)} ä¸ªå¯¹æ¯”æµ‹è¯•\n")

    start_time = time.time()
    results = []

    for idx, case in cases_to_run:
        result = await run_comparison(
            llm, reasoning,
            case["query"], case["description"], idx
        )
        results.append(result)

    duration = time.time() - start_time

    # æ‰“å°æ€»ç»“
    if len(results) > 1:
        print("\n" + "â”" * 70)
        print("ğŸ“Š å¯¹æ¯”æ€»ç»“")
        print("â”" * 70)
        print(f"\n  â±ï¸  æ€»è€—æ—¶: {duration:.1f}s")
        print(f"  ğŸ“ æµ‹è¯•æ•°é‡: {len(results)}")

        avg_generic_len = sum(r["generic_length"] for r in results) / len(results)
        avg_expert_len = sum(r["expert_length"] for r in results) / len(results)
        print(f"\n  é€šç”¨å›ç­”å¹³å‡é•¿åº¦: {avg_generic_len:.0f} å­—")
        print(f"  ä¸“å®¶å›ç­”å¹³å‡é•¿åº¦: {avg_expert_len:.0f} å­—")
        print(f"  ä¸“å®¶å›ç­”é•¿åº¦æ¯”: {avg_expert_len / avg_generic_len:.1%}")

        print(f"\n  é˜¶æ®µåˆ†å¸ƒ:")
        stage_counts = {}
        for r in results:
            stage_counts[r["stage"]] = stage_counts.get(r["stage"], 0) + 1
        for stage, count in sorted(stage_counts.items(), key=lambda x: -x[1]):
            print(f"    {stage}: {count} ä¸ª")

        avg_confidence = sum(r["confidence"] for r in results) / len(results)
        print(f"\n  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.0%}")
        print("\n" + "â”" * 70)


def main():
    parser = argparse.ArgumentParser(description="ä¸“å®¶è§’è‰² A/B å¯¹æ¯”å·¥å…·")
    parser.add_argument(
        "--case",
        type=int,
        default=None,
        help="åªè¿è¡ŒæŒ‡å®šç´¢å¼•çš„æµ‹è¯•ç”¨ä¾‹",
    )
    parser.add_argument(
        "--custom",
        type=str,
        default=None,
        help="è‡ªå®šä¹‰æµ‹è¯•é—®é¢˜",
    )
    args = parser.parse_args()

    print("\nğŸ”¬ ä¸“å®¶è§’è‰² A/B å¯¹æ¯”å·¥å…·")
    print("=" * 70)
    print("å¯¹åŒä¸€é—®é¢˜ï¼Œå¯¹æ¯”ã€Œé€šç”¨é¡¾é—®ã€vsã€Œé˜¶æ®µä¸“å®¶ã€çš„å›ç­”è´¨é‡å·®å¼‚")

    cases = COMPARISON_CASES[:]

    if args.custom:
        cases = [{"query": args.custom, "description": "è‡ªå®šä¹‰é—®é¢˜"}]
        asyncio.run(run_all_comparisons(cases))
    else:
        asyncio.run(run_all_comparisons(cases, args.case))


if __name__ == "__main__":
    main()
